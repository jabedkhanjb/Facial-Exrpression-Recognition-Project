{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabedkhanjb/Facial-Exrpression-Recognition-Project/blob/main/Facial_Expression_Recognition_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b692628",
      "metadata": {
        "id": "0b692628"
      },
      "source": [
        "# Facial Expression Recognition with Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a1eba92",
      "metadata": {
        "id": "3a1eba92"
      },
      "source": [
        "## Dataset Link\n",
        "https://www.kaggle.com/jonathanoheix/face-expression-recognition-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48cd3b5c",
      "metadata": {
        "id": "48cd3b5c"
      },
      "source": [
        "### Install Libraries, Packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00cf1e4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00cf1e4b",
        "outputId": "326b3437-2277-4cd0-f8f1-b7ed7824801c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Facial-Expression-Dataset'...\n",
            "remote: Enumerating objects: 34052, done.\u001b[K\n",
            "remote: Total 34052 (delta 0), reused 0 (delta 0), pack-reused 34052\u001b[K\n",
            "Receiving objects: 100% (34052/34052), 52.31 MiB | 23.97 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (35887/35887), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/parth1620/Facial-Expression-Dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a9b0767a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9b0767a",
        "outputId": "79625e9c-18b7-4867-dcf9-338cf4101326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-05miy_5m\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-05miy_5m\n",
            "  Resolved https://github.com/albumentations-team/albumentations to commit 82818a0c4a80924d9f903a656c7f549ec6ca9cb2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.5.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.9.0.80)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U git+https://github.com/albumentations-team/albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "53a37e0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53a37e0a",
        "outputId": "85c7f45b-9f4e-4b9c-8476-e8668cd2b93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c51a366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c51a366",
        "outputId": "b3123138-064c-4b32-ae08-63dc53b1ac29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.23.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.8.0.76\n",
            "    Uninstalling opencv-contrib-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-contrib-python-4.8.0.76\n",
            "Successfully installed opencv-contrib-python-4.9.0.80\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3174af4f",
      "metadata": {
        "id": "3174af4f"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a5ec479",
      "metadata": {
        "id": "9a5ec479"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "db988cfa",
      "metadata": {
        "id": "db988cfa"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMG_FOLDER_PATH = \"/content/Facial-Expression-Dataset/train\"\n",
        "VALID_IMG_FOLDER_PATH = \"/content/Facial-Expression-Dataset/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8c6de11e",
      "metadata": {
        "id": "8c6de11e"
      },
      "outputs": [],
      "source": [
        "LR = 0.001\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "MODEL_NAME = 'efficientnet_b0'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3391c9ed",
      "metadata": {
        "id": "3391c9ed"
      },
      "source": [
        "Above this part is very important to conduct the whole project, we can change any parameter from this part to conduct our entire model better than before."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86670cad",
      "metadata": {
        "id": "86670cad"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9462c430",
      "metadata": {
        "id": "9462c430"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7a0b1b8a",
      "metadata": {
        "id": "7a0b1b8a"
      },
      "outputs": [],
      "source": [
        "train_augs = T.Compose([\n",
        "    T.RandomHorizontalFlip(p = 0.5),\n",
        "    T.RandomRotation(degrees=(-20, +20)),\n",
        "    T.ToTensor() #PIL / numpy arr -> torch tensor -> (h, w, c) -> (c, h, w)\n",
        "])\n",
        "\n",
        "valid_augs = T.Compose([\n",
        "    T.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "246f2dbe",
      "metadata": {
        "id": "246f2dbe"
      },
      "outputs": [],
      "source": [
        "trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform = train_augs)\n",
        "validset = ImageFolder(VALID_IMG_FOLDER_PATH, transform = train_augs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "26dc210b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26dc210b",
        "outputId": "eabedddc-5533-4a15-b045-f5cc92c3eacf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28821"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7ed80234",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ed80234",
        "outputId": "b6780cc8-3891-4688-d0f3-7d2660ec3003"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7066"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(validset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "16e1be45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16e1be45",
        "outputId": "d5228dc2-1e84-43dc-e6c3-24bc20c67f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    The total number of datasets is 35887,\n",
            "    where the training dataset has 28821 examples,\n",
            "    and the validation dataset has 7066 examples.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"\n",
        "    The total number of datasets is {len(trainset) + len(validset)},\n",
        "    where the training dataset has {len(trainset)} examples,\n",
        "    and the validation dataset has {len(validset)} examples.\n",
        "    \"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add1e0ef",
      "metadata": {
        "id": "add1e0ef"
      },
      "source": [
        "### Plot the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fa5fd692",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa5fd692",
        "outputId": "f186f91c-f1d0-49b0-ca25-ced040904ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ],
      "source": [
        "print(trainset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b2cde7c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "b2cde7c0",
        "outputId": "a3d7a1a9-b193-419d-f498-728553cd89d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image, label = trainset[14]\n",
        "plt.imshow(image.permute(1,2,0)) #(image comes up with height, width and channel)\n",
        "plt.title(label);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ab060d",
      "metadata": {
        "id": "f9ab060d"
      },
      "source": [
        "Here, we see a '0' in the title of the image, which represents the facial expression of the expression depicted in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4fef65",
      "metadata": {
        "id": "7f4fef65"
      },
      "source": [
        "## Load Dataset into Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cf847385",
      "metadata": {
        "id": "cf847385"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8f8ff29c",
      "metadata": {
        "id": "8f8ff29c"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ce1498d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce1498d3",
        "outputId": "c773315b-c57f-4b77-af36-35ba5d4205fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of batches in trainloader : 901\n",
            "Total number of batches in validloader : 221\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of batches in trainloader : {len(trainloader)}\")\n",
        "print(f\"Total number of batches in validloader : {len(validloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "da8ad637",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8ad637",
        "outputId": "c9369f67-cbd9-401f-ea23-b74d6e0458e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One image batch shape torch.Size([32, 3, 48, 48])\n",
            "One image batch shape torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in trainloader:\n",
        "    break;\n",
        "\n",
        "print(f\"One image batch shape {images.shape}\")\n",
        "print(f\"One image batch shape {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f84352e5",
      "metadata": {
        "id": "f84352e5"
      },
      "source": [
        "Here, We can see One image batch shape is 32, 3, 48, 48 which means 32 is the number of images according to the batch size which has been declared before along with \"BATCH_SIZE, EPOCS......\", 3 is the number of channel and 48, 48 is the height and width"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d785e3",
      "metadata": {
        "id": "04d785e3"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1ec69152",
      "metadata": {
        "id": "1ec69152"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0a8dd208",
      "metadata": {
        "id": "0a8dd208"
      },
      "outputs": [],
      "source": [
        "class FaceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceModel, self).__init__()\n",
        "        self.eff_net = timm.create_model('efficientnet_b0', pretrained = True, num_classes = 7)\n",
        "\n",
        "    def forward(self, images, labels = None):\n",
        "        logits = self.eff_net(images)\n",
        "\n",
        "        if labels != None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "            return logits, loss\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "36e912fa",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36e912fa",
        "outputId": "4303fe05-e8d4-4007-d96f-02b5f1a14174"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FaceModel(\n",
              "  (eff_net): EfficientNet(\n",
              "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model = FaceModel()\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1696431f",
      "metadata": {
        "id": "1696431f"
      },
      "source": [
        "# Create Train and Evaluate Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7704f81e",
      "metadata": {
        "id": "7704f81e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b9bfccca",
      "metadata": {
        "id": "b9bfccca"
      },
      "outputs": [],
      "source": [
        "def multiclass_accuracy(y_pred, y_true):\n",
        "    top_p, top_class = y_pred.topk(1, dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "487442c2",
      "metadata": {
        "id": "487442c2"
      },
      "outputs": [],
      "source": [
        "def train_fn(model, dataloader, optimizer, current_epo):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    tk = tqdm(dataloader, desc= \"EPOCH\" + \"[TRAIN]\" + str(current_epo + 1)+ \"/\" + str(EPOCHS))\n",
        "\n",
        "    for t, data in enumerate(tk):\n",
        "        images, labels = data\n",
        "        image, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(images, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits, labels)\n",
        "        tk.set_postfix({'loss' : \"%6f\" %float(total_loss / (t+1)), 'acc' : \"%6f\" %float(total_acc / (t+1)),})\n",
        "\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "afc80fc1",
      "metadata": {
        "id": "afc80fc1"
      },
      "outputs": [],
      "source": [
        "def eval_fn(model, dataloader, current_epo):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    tk = tqdm(dataloader, desc= \"EPOCH\" + \"[VALID]\" + str(current_epo + 1)+ \"/\" + str(EPOCHS))\n",
        "\n",
        "    for t, data in enumerate(tk):\n",
        "        images, labels = data\n",
        "        image, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        logits, loss = model(images, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits, labels)\n",
        "        tk.set_postfix({'loss' : \"%6f\" %float(total_loss / (t+1)), 'acc' : \"%6f\" %float(total_acc / (t+1)),})\n",
        "\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58bfcdd",
      "metadata": {
        "id": "c58bfcdd"
      },
      "source": [
        "# Create Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7a6c8823",
      "metadata": {
        "id": "7a6c8823"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d5dcf62f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5dcf62f",
        "outputId": "1c21b688-0fd9-4e74-8817-c3bfd1be5680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]1/15: 100%|██████████| 901/901 [16:48<00:00,  1.12s/it, loss=1.882308, acc=0.361848]\n",
            "EPOCH[VALID]1/15: 100%|██████████| 221/221 [00:37<00:00,  5.87it/s, loss=1.363459, acc=0.484859]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]2/15: 100%|██████████| 901/901 [16:28<00:00,  1.10s/it, loss=1.332869, acc=0.493835]\n",
            "EPOCH[VALID]2/15: 100%|██████████| 221/221 [00:39<00:00,  5.64it/s, loss=1.254771, acc=0.521765]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]3/15: 100%|██████████| 901/901 [16:39<00:00,  1.11s/it, loss=1.223875, acc=0.536043]\n",
            "EPOCH[VALID]3/15: 100%|██████████| 221/221 [00:36<00:00,  6.06it/s, loss=1.165015, acc=0.561956]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]4/15: 100%|██████████| 901/901 [16:27<00:00,  1.10s/it, loss=1.158803, acc=0.563116]\n",
            "EPOCH[VALID]4/15: 100%|██████████| 221/221 [00:38<00:00,  5.78it/s, loss=1.121384, acc=0.577445]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]5/15: 100%|██████████| 901/901 [16:25<00:00,  1.09s/it, loss=1.123996, acc=0.576646]\n",
            "EPOCH[VALID]5/15: 100%|██████████| 221/221 [00:37<00:00,  5.88it/s, loss=1.101105, acc=0.581132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]6/15: 100%|██████████| 901/901 [16:28<00:00,  1.10s/it, loss=1.098489, acc=0.591089]\n",
            "EPOCH[VALID]6/15: 100%|██████████| 221/221 [00:37<00:00,  5.90it/s, loss=1.090082, acc=0.591890]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]7/15: 100%|██████████| 901/901 [16:25<00:00,  1.09s/it, loss=1.066123, acc=0.598216]\n",
            "EPOCH[VALID]7/15: 100%|██████████| 221/221 [00:39<00:00,  5.58it/s, loss=1.115953, acc=0.582568]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]8/15: 100%|██████████| 901/901 [16:22<00:00,  1.09s/it, loss=1.037007, acc=0.614089]\n",
            "EPOCH[VALID]8/15: 100%|██████████| 221/221 [00:40<00:00,  5.40it/s, loss=1.088942, acc=0.608576]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]9/15: 100%|██████████| 901/901 [16:15<00:00,  1.08s/it, loss=1.016852, acc=0.617188]\n",
            "EPOCH[VALID]9/15: 100%|██████████| 221/221 [00:41<00:00,  5.37it/s, loss=1.107637, acc=0.592053]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]10/15: 100%|██████████| 901/901 [16:29<00:00,  1.10s/it, loss=0.984403, acc=0.634825]\n",
            "EPOCH[VALID]10/15: 100%|██████████| 221/221 [00:38<00:00,  5.73it/s, loss=1.047524, acc=0.614732]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]11/15: 100%|██████████| 901/901 [16:22<00:00,  1.09s/it, loss=0.952395, acc=0.643914]\n",
            "EPOCH[VALID]11/15: 100%|██████████| 221/221 [00:38<00:00,  5.77it/s, loss=1.006338, acc=0.632168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]12/15: 100%|██████████| 901/901 [16:04<00:00,  1.07s/it, loss=0.929324, acc=0.655239]\n",
            "EPOCH[VALID]12/15: 100%|██████████| 221/221 [00:39<00:00,  5.55it/s, loss=1.022625, acc=0.623075]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]13/15: 100%|██████████| 901/901 [16:08<00:00,  1.07s/it, loss=0.902412, acc=0.663851]\n",
            "EPOCH[VALID]13/15: 100%|██████████| 221/221 [00:37<00:00,  5.89it/s, loss=1.018280, acc=0.625130]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]14/15: 100%|██████████| 901/901 [16:10<00:00,  1.08s/it, loss=0.867643, acc=0.674921]\n",
            "EPOCH[VALID]14/15: 100%|██████████| 221/221 [00:40<00:00,  5.49it/s, loss=1.031037, acc=0.622901]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]15/15: 100%|██████████| 901/901 [16:29<00:00,  1.10s/it, loss=0.846114, acc=0.688417]\n",
            "EPOCH[VALID]15/15: 100%|██████████| 221/221 [00:37<00:00,  5.82it/s, loss=1.009694, acc=0.633647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = np.Inf\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    train_loss, train_acc = train_fn(model, trainloader, optimizer, i) # \"i\" is the current epoch\n",
        "    valid_loss, valid_acc = eval_fn(model, validloader, i)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        torch.save(model.state_dict(), \"best-weights.pt\")\n",
        "        print(\"SAVED-BEST-WEIGHTS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0a1545",
      "metadata": {
        "id": "7f0a1545"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}