{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfc0211",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb35b5",
   "metadata": {},
   "source": [
    "## Dataset Link\n",
    "https://www.kaggle.com/jonathanoheix/face-expression-recognition-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df42edf",
   "metadata": {},
   "source": [
    "### Install Libraries, Packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81238605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20473) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Facial-Expression-Dataset' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/parth1620/Facial-Expression-Dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c609a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20476) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/albumentations-team/albumentations\n",
      "  Cloning https://github.com/albumentations-team/albumentations to /private/var/folders/_x/kvs2mx1s5bs08dcbp6_xfwfc0000gn/T/pip-req-build-nhnjsujt\n",
      "  Running command git clone --quiet https://github.com/albumentations-team/albumentations /private/var/folders/_x/kvs2mx1s5bs08dcbp6_xfwfc0000gn/T/pip-req-build-nhnjsujt\n",
      "  Resolved https://github.com/albumentations-team/albumentations to commit 82818a0c4a80924d9f903a656c7f549ec6ca9cb2\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from albumentations==1.3.1) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from albumentations==1.3.1) (1.10.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from albumentations==1.3.1) (0.19.3)\n",
      "Requirement already satisfied: PyYAML in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from albumentations==1.3.1) (6.0)\n",
      "Collecting qudida>=0.0.4 (from albumentations==1.3.1)\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations==1.3.1)\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.8.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.26.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (22.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (2.2.0)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m605.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for albumentations: filename=albumentations-1.3.1-py3-none-any.whl size=125877 sha256=b168e7ec37457264cffa421c8a079c2fd8c07779ce378355cd4303c60582bbce\n",
      "  Stored in directory: /private/var/folders/_x/kvs2mx1s5bs08dcbp6_xfwfc0000gn/T/pip-ephem-wheel-cache-0a6fuh8t/wheels/51/4d/ab/5aafa8b980086fbc362946de7da4aa3df33aacb3da0da29b93\n",
      "Successfully built albumentations\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.1 opencv-python-headless-4.9.0.80 qudida-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/albumentations-team/albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f51dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m572.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from timm) (1.12.1)\n",
      "Collecting torchvision (from timm)\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from timm) (0.10.1)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing_extensions in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from huggingface-hub->timm) (3.13.1)\n",
      "Requirement already satisfied: requests in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from huggingface-hub->timm) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from huggingface-hub->timm) (22.0)\n",
      "Requirement already satisfied: numpy in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\n",
      "Collecting torch>=1.7 (from timm)\n",
      "  Downloading torch-2.1.2-cp310-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: sympy in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torch>=1.7->timm) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from torch>=1.7->timm) (2022.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.7->timm) (1.2.1)\n",
      "Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m648.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-macosx_11_0_arm64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m703.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp310-cp310-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m434.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m449.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, torch, torchvision, timm\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed safetensors-0.4.1 timm-0.9.12 torch-2.1.2 torchvision-0.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db77946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(20534) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/jabedkhanjb/Anaconda/anaconda3/lib/python3.10/site-packages (from opencv-contrib-python) (1.23.5)\n",
      "Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (44.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m600.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88d228",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f5c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b61cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_FOLDER_PATH = \"/Volumes/MacOS Disk 1/Mac Jupyter Notebook/Facial Expression ML/Facial-Expression-Dataset/train\"\n",
    "VALID_IMG_FOLDER_PATH = \"/Volumes/MacOS Disk 1/Mac Jupyter Notebook/Facial Expression ML/Facial-Expression-Dataset/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42a55270",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "MODEL_NAME = 'efficientnet_b0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d0da3",
   "metadata": {},
   "source": [
    "Above this part is very important to conduct the whole project, we can change any parameter from this part to conduct our entire model better than before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbce193",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe2b914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83b7d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augs = T.Compose([\n",
    "    T.RandomHorizontalFlip(p = 0.5),\n",
    "    T.RandomRotation(degrees=(-20, +20)),\n",
    "    T.ToTensor() #PIL / numpy arr -> torch tensor -> (h, w, c) -> (c, h, w)\n",
    "])\n",
    "\n",
    "valid_augs = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4104a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform = train_augs)\n",
    "validset = ImageFolder(VALID_IMG_FOLDER_PATH, transform = train_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb2d237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28821"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d06a96db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7066"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e71bd340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The total number of datasets is 35887,\n",
      "    where the training dataset has 28821 examples,\n",
      "    and the validation dataset has 7066 examples.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    The total number of datasets is {len(trainset) + len(validset)},\n",
    "    where the training dataset has {len(trainset)} examples,\n",
    "    and the validation dataset has {len(validset)} examples.\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd731f",
   "metadata": {},
   "source": [
    "### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50673b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "print(trainset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe9efab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = trainset[14]\n",
    "plt.imshow(image.permute(1,2,0)) #(image comes up with height, width and channel)\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf093056",
   "metadata": {},
   "source": [
    "Here, we see a '0' in the title of the image, which represents the facial expression of the expression depicted in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98816da5",
   "metadata": {},
   "source": [
    "## Load Dataset into Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afb00cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bc45c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "validloader = DataLoader(validset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56249ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches in trainloader : 901\n",
      "Total number of batches in validloader : 221\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"Total number of batches in validloader : {len(validloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5687a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image batch shape torch.Size([32, 3, 48, 48])\n",
      "One image batch shape torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader:\n",
    "    break;\n",
    "\n",
    "print(f\"One image batch shape {images.shape}\")\n",
    "print(f\"One image batch shape {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8febc0",
   "metadata": {},
   "source": [
    "Here, We can see One image batch shape is 32, 3, 48, 48 which means 32 is the number of images according to the batch size which has been declared before along with \"BATCH_SIZE, EPOCS......\", 3 is the number of channel and 48, 48 is the height and width "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa83d4",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e65283fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6958478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceModel, self).__init__()\n",
    "        self.eff_net = timm.create_model('efficientnet_b0', pretrained = True, num_classes = 7)\n",
    "    \n",
    "    def forward(self, images, labels = None):\n",
    "        logits = self.eff_net(images)\n",
    "        \n",
    "        if labels != None:\n",
    "            loss = nn.CrossEntropyLoss()(logts, labels)\n",
    "            return logits, loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a02c78a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaceModel(\n",
       "  (eff_net): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1280, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FaceModel()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad32d9",
   "metadata": {},
   "source": [
    "# Create Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40130fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "198b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutliclass_accuracy(y_pred, y_true):\n",
    "    top_p, top_class = y_pred.t0pk(1, dim = 1)\n",
    "    equals = top_class == y_true.view(*top_class.shape)\n",
    "    return torch.mean(equals.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a60a144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, dataloader, optimizer, current_epo):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    tk = tqdm(dataloader, desc= \"EPOCH\" + \"[TRAIN]\" + str(current_epo + 1)+ \"/\" + str(EPOCHS))\n",
    "    \n",
    "    for t, data in enumerate(tk):\n",
    "        images, labels = data\n",
    "        image, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(images, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += multiclass_accuracy(logits, labels)\n",
    "        tk.set_postfix({'loss' : \"%6f\" %float(total_loss / (t+1)), 'acc' : \"%6f\" %float(total_acc / (t+1)),})\n",
    "        \n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0899993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, dataloader, current_epo):\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    tk = tqdm(dataloader, desc= \"EPOCH\" + \"[VALID]\" + str(current_epo + 1)+ \"/\" + str(EPOCHS))\n",
    "    \n",
    "    for t, data in enumerate(tk):\n",
    "        images, labels = data\n",
    "        image, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        logits, loss = model(images, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += multiclass_accuracy(logits, labels)\n",
    "        tk.set_postfix({'loss' : \"%6f\" %float(total_loss / (t+1)), 'acc' : \"%6f\" %float(total_acc / (t+1)),})\n",
    "        \n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8733f76",
   "metadata": {},
   "source": [
    "# Create Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c044b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0382e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]1/15:   0%|                                 | 0/901 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mInf\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 4\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# \"i\" is the current epoch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m eval_fn(model, validloader, i)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[0;32mIn[114], line 13\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, dataloader, optimizer, current_epo)\u001b[0m\n\u001b[1;32m     10\u001b[0m image, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(DEVICE), labels\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[80], line 10\u001b[0m, in \u001b[0;36mFaceModel.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meff_net(images)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(\u001b[43mlogts\u001b[49m, labels)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, loss\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logts' is not defined"
     ]
    }
   ],
   "source": [
    "best_valid_loss = np.Inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train_loss, train_acc = train_fn(model, trainloader, optimizer, i) # \"i\" is the current epoch\n",
    "    valid_loss, valid_acc = eval_fn(model, validloader, i)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        torch.save(model.state_dict(), \"best-weights.pt\")\n",
    "        print(\"SAVED-BEST-WEIGHTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc326697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
